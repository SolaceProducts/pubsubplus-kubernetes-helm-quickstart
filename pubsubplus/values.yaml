solace:
  # solace.redundancy=false will create a single-node non-HA deployment;
  #  true will create an HA deployment with Primary, Backup and Monitor nodes.
  redundancy: false

  # Deployment scaling tier with max # of connections, see README for valid options
  #  dev uses minimum resources but performance is not guaranteed; use prod for production-ready
  size: prod100

  # usernameAdminPassword sets the password for the management user "admin".
  # If empty, a password will be autogenerated but note that for upgrade you need to
  #  obtain the generated password and provide it for each upgrade. 
  # Obtain the generated password from the deployment using
  #   kubectl get secret <release-name>-solace-secrets -o jsonpath="{.data.username_admin_password}" | base64 --decode
  usernameAdminPassword:

image:
  # Default repository is the public Solace DockerHub repo
  repository: solace/solace-pubsub-standard
  # Recommending to use a specific version tag for production
  tag: latest

  # Specify if not using default IfNotPresent
  # pullPolicy: IfNotPresent

  # Provide an existing ImagePullSecret's name if using secure image repo.
  # pullSecretName:

service:
  # service.type specifies how to expose the service: options include ClusterIP, NodePort, LoadBalancer (default if not specified)
  type: LoadBalancer

  # service.annotations allows to add provider-specific service annotations, see example below
  # annotations: cloud.google.com/load-balancer-type: "internal"

  # List here all ports to be exposed as external service.
  #    "containerPorts" (from the PubSub+ container) will be exposed as external "servicePorts",
  # Refer to the Solace documentation of Default Port Numbers for the containerPorts.
  ports:
      - servicePort: 22
        containerPort: 2222
        protocol: TCP
        name: ssh
      - servicePort: 8080
        containerPort: 8080
        protocol: TCP
        name: semp
      - servicePort: 943
        containerPort: 60943
        protocol: TCP
        name: semptls
      - servicePort: 55555
        containerPort: 55555
        protocol: TCP
        name: smf
      - servicePort: 55003
        containerPort: 55003
        protocol: TCP
        name: smfcomp
      - servicePort: 55443
        containerPort: 55443
        protocol: TCP
        name: smftls
      - servicePort: 80
        containerPort: 60080
        protocol: TCP
        name: web
      - servicePort: 443
        containerPort: 60443
        protocol: TCP
        name: webtls
      - servicePort: 5672
        containerPort: 5672
        protocol: TCP
        name: amqp
      - servicePort: 1883
        containerPort: 1883
        protocol: TCP
        name: mqtt
      - servicePort: 9000
        containerPort: 9000
        protocol: TCP
        name: rest
  #   - servicePort: 5671
  #     containerPort: 5671
  #     protocol: TCP
  #     name: amqptls
  #   - servicePort: 8883
  #     containerPort: 8883
  #     protocol: TCP
  #     name: mqtttls
  #   - servicePort: 8000
  #     containerPort: 8000
  #     protocol: TCP
  #     name: mqttws
  #   - servicePort: 8443
  #     containerPort: 8443
  #     protocol: TCP
  #     name: mqttwss
  #   - servicePort: 9443
  #     containerPort: 9443
  #     protocol: TCP
  #     name: resttls

storage:
  # storage.persistent set to false will use ephemeral storage and the rest of the storage params will be ignored
  #  false is not recommended for production use
  persistent: true

  # storage.customVolumeMount enables specifying a yaml snippet how the data volume should be mounted.
  #   If customVolumeMount is defined the rest of the storage params will be ignored
  #   This example shows how to mount the PubSub+ data volume from an existing pvc "test-claim"
  # customVolumeMount: |
  # persistentVolumeClaim:
  #   claimName: test-claim

  # storage.nfs=true specifies that an NFS storage is used. Default is false. Also provide storage.useStorageClass
  # nfs: true

  # storage.useStorageClass will be used if specified, verify it exists using `kubectl get sc`.
  # If not defined, the deployment will try to use the default storage class for the k8s cluster.
  # useStorageClass: standard

  # Refer to the Solace documentation for Minimum Recommended Storage-Element Size per Scaling Tier
  size: 30Gi


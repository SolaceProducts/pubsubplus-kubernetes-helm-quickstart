
== Check Solace PubSub+ deployment progress ==
Deployment is complete when a PubSub+ pod representing an active event broker node's label reports "active=true".
Watch progress by running:
   kubectl get pods --namespace {{ .Release.Namespace }} --show-labels -w | grep {{ template "solace.fullname" . }}

For troubleshooting, refer to ***TroubleShooting.md***

== Admin credentials and access ==
{{- if not .Values.solace.usernameAdminPassword }}
*********************************************************************
* An admin password was not specified and has been auto-generated.
* You must retrieve it and provide it as value override
* if using Helm upgrade otherwise your cluster will become unusable.
*********************************************************************

{{- end }}
    Username       : admin
    Admin password : echo `kubectl get secret --namespace {{ .Release.Namespace }} {{ template "solace.fullname" . }}-secrets -o jsonpath="{.data.username_admin_password}" | base64 --decode`
    Use the "semp" service address to access the management API via browser or a REST tool, see Services access below.

== Image used ==
{{ .Values.image.repository }}:{{ .Values.image.tag }}

== Storage used ==
{{- if and ( .Values.storage.persistent ) ( .Values.storage.useStorageClass ) }}
Using persistent volumes via dynamic provisioning, ensure specified StorageClass exists: `kubectl get sc {{ .Values.storage.useStorageClass }}`
{{- else if  .Values.storage.persistent}}
Using persistent volumes via dynamic provisioning with the "default" StorageClass, ensure it exists: `kubectl get sc | grep default`
{{- end }}
{{- if and ( not .Values.storage.persistent ) ( not .Values.storage.hostPath ) ( not .Values.storage.existingVolume ) }}
*******************************************************************************
* This deployment is using pod-local ephemeral storage.
* Note that any configuration and stored messages will be lost at pod restart.
*******************************************************************************
For production purposes it is recommended to use persistent storage.
{{- end }}

== Performance and resource requirements ==
{{- if contains "dev" .Values.solace.size }}
This is a minimum footprint deployment for development purposes. For guaranteed performance, specify a different solace.size value.
{{- else }}
The requested connection scaling tier for this deployment is: max {{ substr 4 10 .Values.solace.size }} connections. 
{{- end }}
Following resources have been requested per PubSub+ pod:
    echo `kubectl get statefulset --namespace {{ .Release.Namespace }} {{ template "solace.fullname" . }} -o jsonpath="Minimum resources: {.spec.template.spec.containers[0].resources.requests}"`

== Services access ==
To access services from pods within the k8s cluster, use these addresses:

    echo -e "\nProtocol\tAddress\n"`kubectl get svc --namespace {{ .Release.Namespace }} {{ template "solace.fullname" . }} -o jsonpath="{range .spec.ports[*]}{.name}\t{{ template "solace.fullname" . }}.{{ .Release.Namespace }}.svc.cluster.local:{.port}\n"`

To access from outside the k8s cluster, perform the following steps.

{{- if contains "NodePort" .Values.service.type }}

Obtain the NodePort IP and service ports:

    export NODE_IP=$(kubectl get nodes --namespace {{ .Release.Namespace }} -o jsonpath="{.items[*].status.addresses[0].address}"); echo $NODE_IP
    # Use following ports with any of the NodeIPs
    echo -e "\nProtocol\tAddress\n"`kubectl get svc --namespace {{ .Release.Namespace }} {{ template "solace.fullname" . }} -o jsonpath="{range .spec.ports[*]}{.name}\t<NodeIP>:{.nodePort}\n"`

{{- else if contains "LoadBalancer" .Values.service.type }}

Obtain the LoadBalancer IP and the service addresses:
NOTE: At initial deployment it may take a few minutes for the LoadBalancer IP to be available.
      Watch the status with: 'kubectl get svc --namespace {{ .Release.Namespace }} -w {{ template "solace.fullname" . }}'

    export SERVICE_IP=$(kubectl get svc --namespace {{ .Release.Namespace }} {{ template "solace.fullname" . }} --template "{{"{{ range (index .status.loadBalancer.ingress 0) }}{{.}}{{ end }}"}}"); echo SERVICE_IP=$SERVICE_IP
    # Ensure valid SERVICE_IP is returned:
    echo -e "\nProtocol\tAddress\n"`kubectl get svc --namespace {{ .Release.Namespace }} {{ template "solace.fullname" . }} -o jsonpath="{range .spec.ports[*]}{.name}\t$SERVICE_IP:{.port}\n"`

{{- else if contains "ClusterIP"  .Values.service.type }}

NOTE: The specified k8s service type for this deployment is "ClusterIP" and it is not exposing services externally.

For local testing purposes you can use port-forward in a background process to map pod ports to local host, then use these service addresses:

    kubectl port-forward --namespace {{ .Release.Namespace }} svc/{{ template "solace.fullname" . }} $(echo `kubectl get svc --namespace {{ .Release.Namespace }} {{ template "solace.fullname" . }} -o jsonpath="{range .spec.ports[*]}{.targetPort}:{.port} "`) &
    echo -e "\nProtocol\tAddress\n"`kubectl get svc --namespace {{ .Release.Namespace }} {{ template "solace.fullname" . }} -o jsonpath="{range .spec.ports[*]}{.name}\t127.0.0.1:{.targetPort}\n"`

{{- end }}
